Model Name,F1-Score,Precision,Recall
athene-v2:72b,0.6720937158741189,0.7587984756780991,0.6031717747683535
aya-expanse:32b,0.5067117640841349,0.622759158222915,0.4271204561653599
aya-expanse:8b,0.4871339840283939,0.645123384253819,0.391304347826087
command-r-plus:104b,0.4240009658336351,0.6574316735305129,0.3129009265858874
command-r:35b,0.6175637393767704,0.7947279865395401,0.5049893086243763
firefunction-v2:70b,0.5933087117097546,0.7598775737340011,0.4866357804704206
gpt-4o,0.7390874975311081,0.8289765175011077,0.6667854597291518
granite3-dense:8b,0.2180515759312321,0.5562865497076024,0.1356022808267997
granite3.1-dense:8b,0.4205233687578562,0.5861739407454604,0.3278688524590164
granite3.1-moe:3b,0.3211346080790173,0.5549234135667396,0.225944404846757
hermes3:405b,0.6635573457706168,0.8189429618001046,0.5577334283677833
hermes3:70b,0.5580016934801015,0.6871741397288843,0.4697077690662865
hermes3:8b,0.5054095826893354,0.6642484039466048,0.4078759800427655
llama3.1:405b,0.6719342604298357,0.8219072164948453,0.5682466143977192
llama3.1:405b-instruct-q8,0.6936682365253795,0.8404767943190464,0.590520313613685
llama3.1:70b,0.5520224962145793,0.7022564667033572,0.4547398431931575
llama3.1:8b,0.4547461368653422,0.5974477958236659,0.3670705630791162
llama3.2:3b,0.3835227272727273,0.5712270803949224,0.2886671418389166
llama3.3:70b,0.6806670784434836,0.8059483178937104,0.5890947968638631
llama3.3:70b-instruct-fp16,0.6829872947009606,0.8124846399606783,0.5890947968638631
mistral-small:24b,0.6657926583299717,0.7669609665427509,0.5882038488952245
mixtral:8x22b,0.5193236714975846,0.676487414187643,0.4214183891660727
nemotron:70b,0.6594332666175077,0.8064931718629219,0.5577334283677833
qwen2.5-coder:32b,0.612819716267992,0.7315203955500618,0.5272630078403421
qwen2.5:72b,0.6628447168132845,0.7442841287458379,0.5974697077690663
